{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import itertools \n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, LinearLocator, AutoMinorLocator\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from statsmodels.stats.multitest import multipletests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad6a2bba",
   "metadata": {},
   "source": [
    "### Description:\n",
    "This notebook contains code to test for the similarity of the distance matrices. We test whether the embedding matrices produced with different subset of data are statistically similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324abc0c-94b8-4bcf-8192-bd08936af1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis for version 1.33\n",
    "v = \"4.02\"#\"1.33\"\n",
    "subset_versions = [\"9.0\" , \"9.11\", \"9.21\"]\n",
    "save_path = r\"../%s/\" %v\n",
    "data_path = r\"../token_embeddings/tensors.tsv\"\n",
    "vocab_path = r\"../global_set/result.tsv\"\n",
    "paths = [data_path %sv for sv in subset_versions]\n",
    "\n",
    "vocab = pd.read_csv(vocab_path, sep=\"\\t\").set_index(\"ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e29cb-7cf9-48b4-b136-c7582c9caf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper(df):\n",
    "    '''Returns the upper triangle of a correlation matrix.\n",
    "    You can use scipy.spatial.distance.squareform to recreate matrix from upper triangle.\n",
    "    Args:\n",
    "      df: pandas or numpy correlation matrix\n",
    "    Returns:\n",
    "      list of values from upper triangle\n",
    "    '''\n",
    "    try:\n",
    "        assert(type(df)==np.ndarray)\n",
    "    except:\n",
    "        if type(df)==pd.DataFrame:\n",
    "            df = df.values\n",
    "        else:\n",
    "            raise TypeError('Must be np.ndarray or pd.DataFrame')\n",
    "    mask = np.triu_indices(df.shape[0], k=1)\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_random_pairs(numbers:list, num_pairs: int): \n",
    "    \"\"\"Generate random integer pairs\"\"\"\n",
    "    random.seed(0)\n",
    "    pairs = list(itertools.combinations(numbers, 2)) \n",
    "    random.shuffle(pairs)\n",
    "    pairs = pairs[:num_pairs]\n",
    "    return pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cosine distances\n",
    "def dot_product2(v1, v2):\n",
    "    return sum(map(operator.mul, v1, v2))\n",
    "    \n",
    "def vector_cos(v1, v2):\n",
    "    prod = dot_product2(v1, v2)\n",
    "    len1 = math.sqrt(dot_product2(v1, v1))\n",
    "    len2 = math.sqrt(dot_product2(v2, v2))\n",
    "    return prod / (len1 * len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, pairs):\n",
    "    euclidean_dist = []\n",
    "    cosine_dist = []\n",
    "    for pair in pairs: \n",
    "        a = x[pair[0]]\n",
    "        b = x[pair[1]]\n",
    "        euclidean_dist.append(np.linalg.norm(a-b))\n",
    "        cosine_dist.append(vector_cos(a,b))\n",
    "    return euclidean_dist, cosine_dist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2043\n",
    "pairs = get_random_pairs([i for i in range(7, vocab_size)], num_pairs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9cbc6-8ccc-4ff7-ab1a-5c0f9bf275d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "embeddings = list()\n",
    "for path in paths:\n",
    "    e = pd.read_csv(path, sep=\"\\t\", header=None).values\n",
    "    mu = e.sum(0) / (vocab.shape[0] - 6)\n",
    "    e= e - mu\n",
    "    embeddings.append(e)\n",
    "permuted = deepcopy(embeddings[0])\n",
    "for i in range(e.shape[1]):\n",
    "    permuted[:,i] = np.random.permutation(permuted[:,i])\n",
    "randome = np.random.normal(permuted.mean(), permuted.std(), size=permuted.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "completed-graham",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_1, cos_1 = pairwise_distances(embeddings[0], pairs)\n",
    "eucl_2, cos_2 = pairwise_distances(embeddings[1], pairs)\n",
    "eucl_3, cos_3 = pairwise_distances(embeddings[2], pairs)\n",
    "eucl_r, cos_r = pairwise_distances(randome, pairs)\n",
    "eucl_p, cos_p = pairwise_distances(permuted, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_points = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(coefs, x, y, max_accept_deviation: int = 1):\n",
    "    fn = np.poly1d(coefs)\n",
    "    residual = np.abs(y - fn(x))\n",
    "    return max_accept_deviation < residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear fit\n",
    "coef_1 = np.polyfit(eucl_1[:max_points], eucl_2[:max_points], 1)\n",
    "poly_1_fn = np.poly1d(coef_1)\n",
    "### \n",
    "coef_2 = np.polyfit(eucl_1[:max_points], eucl_3[:max_points], 1)\n",
    "poly_2_fn = np.poly1d(coef_1)\n",
    "\n",
    "#####\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "ax[0].set_title(\"Pairwise Euclidean Distances (distance comparison)\")\n",
    "ax[0].set_xlabel(\"Distance (Set X)\")\n",
    "ax[0].set_ylabel(\"Distance (Set Y)\")\n",
    "ax[0].scatter(eucl_1[:max_points], eucl_2[:max_points], s=5)\n",
    "ax[0].scatter(eucl_1[:max_points], eucl_3[:max_points], s=5)\n",
    "\n",
    "ax[0].scatter(eucl_1[:max_points], eucl_p[:max_points], s=5, alpha=0.3, marker=\"*\")\n",
    "ax[0].legend([\"Set 1 vs Set 2\", \"Set 1 vs Set 3\", \"Set 1 vs Permuted\"])\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot(eucl_1, poly_1_fn(eucl_1), linestyle=\"dashed\", alpha = 0.5)\n",
    "ax[0].plot(eucl_1, poly_2_fn(eucl_1), linestyle=\"dashed\", alpha = 0.5)\n",
    "ax[0].axis(\"scaled\")\n",
    "\n",
    "ax[0].tick_params(axis= \"both\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[0].tick_params(axis= \"both\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "\n",
    "ax[0].yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "ax[0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "ax[0].xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Distribution of Pairwise Euclidean Distances\")\n",
    "ax[1].set_xlabel(\"Euclidean Distance\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "bins = np.linspace(start=0, stop=12, num=50)\n",
    "\n",
    "ax[1].hist(eucl_r, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"red\")\n",
    "ax[1].hist(eucl_p, density = True, bins=bins, histtype=\"stepfilled\", alpha= 0.3, color=\"orange\")\n",
    "ax[1].hist(eucl_1, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"gray\")\n",
    "ax[1].hist(eucl_2, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"green\")\n",
    "ax[1].hist(eucl_3, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"blue\")\n",
    "\n",
    "ax[1].hist(eucl_r, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"red\")\n",
    "ax[1].hist(eucl_p, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"orange\")\n",
    "ax[1].hist(eucl_1, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"gray\")\n",
    "ax[1].hist(eucl_2, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"green\")\n",
    "ax[1].hist(eucl_3, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"blue\")\n",
    "\n",
    "ax[1].legend([ \"Random\", \"Permuted\", \"Set 1\", \"Set 2\", \"Set 3\"])\n",
    "\n",
    "ax[1].tick_params(axis= \"both\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[1].tick_params(axis= \"both\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "\n",
    "ax[1].yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "ax[1].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "ax[1].xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax[1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig(save_path + \"/life_emb_pairwise_euclidean.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear fit\n",
    "coef_1 = np.polyfit(cos_1[:max_points], cos_2[:max_points], 1)\n",
    "poly_1_fn = np.poly1d(coef_1)\n",
    "### \n",
    "coef_2 = np.polyfit(cos_1[:max_points], cos_3[:max_points], 1)\n",
    "poly_2_fn = np.poly1d(coef_2)\n",
    "#####\n",
    "coef_3 = np.polyfit(cos_2[:max_points], cos_3[:max_points], 1)\n",
    "poly_3_fn = np.poly1d(coef_3)\n",
    "\n",
    "#####\n",
    "coef_4 = np.polyfit(cos_1[:max_points], cos_p[:max_points], 1)\n",
    "poly_4_fn = np.poly1d(coef_4)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "ax[0].set_title(\"Pairwise Cosine Distances (distance comparison)\")\n",
    "ax[0].set_xlabel(\"Distance (Set X)\")\n",
    "ax[0].set_ylabel(\"Distance (Set Y)\")\n",
    "ax[0].scatter(cos_1[:max_points], cos_2[:max_points], marker=\".\", s=5)\n",
    "ax[0].scatter(cos_1[:max_points], cos_3[:max_points], marker=\".\", s=5)\n",
    "ax[0].scatter(cos_2[:max_points], cos_3[:max_points], marker=\".\", s=5)\n",
    "ax[0].scatter(cos_1[:max_points], cos_p[:max_points], alpha=0.3, s=5, marker=\".\", color=\"grey\")\n",
    "plt.legend([\"Set 1 vs Set 2\", \"Set 1 vs Set 3\", \"Set 2 vs Set 3\", \"Set 1 vs Permuted\"])\n",
    "\n",
    "\n",
    "ax[0].plot(cos_1, poly_1_fn(cos_1), linestyle=\"dashed\", alpha = 0.2)\n",
    "ax[0].plot(cos_1, poly_2_fn(cos_1), linestyle=\"dashed\", alpha = 0.2)\n",
    "ax[0].plot(cos_2, poly_3_fn(cos_2), linestyle=\"dashed\", alpha = 0.2)\n",
    "ax[0].plot(cos_1, poly_4_fn(cos_1), linestyle=\"dashed\", alpha = 0.2)\n",
    "ax[0].axis(\"scaled\")\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Distribution of Pairwise Cosine Distances\")\n",
    "ax[1].set_xlabel(\"Pairwise Distance\")\n",
    "ax[1].set_ylabel(\"Distribution\")\n",
    "\n",
    "ax[0].tick_params(axis= \"both\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[0].tick_params(axis= \"both\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "\n",
    "ax[0].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax[0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "ax[0].xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "bins = np.linspace(start=-0.5, stop=1, num=50)\n",
    "\n",
    "ax[1].hist(cos_r, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"red\")\n",
    "ax[1].hist(cos_p,  density = True, bins=bins, histtype=\"stepfilled\", alpha= 0.3, color=\"orange\")\n",
    "ax[1].hist(cos_1, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"gray\")\n",
    "ax[1].hist(cos_2, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"green\")\n",
    "ax[1].hist(cos_3, density = True, bins=bins, histtype=\"stepfilled\", alpha=0.3, color=\"blue\")\n",
    "\n",
    "\n",
    "ax[1].hist(cos_r, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"red\")\n",
    "ax[1].hist(cos_p,  density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"orange\")\n",
    "ax[1].hist(cos_1, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"gray\")\n",
    "ax[1].hist(cos_2, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"green\")\n",
    "ax[1].hist(cos_3, density = True, bins=bins, histtype=\"step\", linewidth=2.5, color=\"blue\")\n",
    "\n",
    "ax[1].legend([\"Random Embedding\", \"Permuted Embedding\", \"Set 1\", \"Set 2\", \"Set 3\"])\n",
    "\n",
    "ax[1].tick_params(axis= \"both\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[1].tick_params(axis= \"both\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "\n",
    "ax[1].yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax[1].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "ax[1].xaxis.set_major_locator(MultipleLocator(0.2))\n",
    "ax[1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig(save_path + \"/life_emb_pairwise_cosine.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98307a4d-8cd2-41e0-bb0a-e80bfe706508",
   "metadata": {},
   "source": [
    "### Permutation Test (Statistical Significance)\n",
    "Comparing:c1 -> c2, c3, cr, cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = cosine_distances(embeddings[0])\n",
    "c2 = cosine_distances(embeddings[1])\n",
    "c3 = cosine_distances(embeddings[2])\n",
    "cp = cosine_distances(permuted)\n",
    "cr = cosine_distances(randome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(upper(c1), upper(c2)), stats.spearmanr(upper(c1), upper(cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37356564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(a, b, n_iter: int = 5000):\n",
    "    \"\"\"Nonparametric permutation testing Monte Carlo\"\"\"\n",
    "    m1 = pd.DataFrame(a)\n",
    "    m2 = pd.DataFrame(b)\n",
    "    np.random.seed(0)\n",
    "    rhos = []\n",
    "    true_rho, _ = stats.spearmanr(upper(m1), upper(m2))\n",
    "    # matrix permutation, shuffle the groups\n",
    "    m_ids = list(m1.columns)\n",
    "    m2_v = upper(m2)\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        np.random.shuffle(m_ids) # shuffle list \n",
    "        r, _ = stats.spearmanr(upper(m1.loc[m_ids, m_ids]), m2_v)  \n",
    "        rhos.append(r)\n",
    "    return ((np.sum(np.abs(true_rho) <= np.abs(rhos)))+1)/(n_iter+1) # two-tailed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca129fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "print(\"1 vs 2\")\n",
    "p12 = permutation_test(c1,c2)\n",
    "clear_output()\n",
    "print(p12)\n",
    "print(\"1 vs 3\")\n",
    "p13 = permutation_test(c1,c3)\n",
    "clear_output()\n",
    "print(p12, p13)\n",
    "print(\"2 vs 3\")\n",
    "p23 = permutation_test(c2,c3)\n",
    "clear_output()\n",
    "print(p12, p13, p23)\n",
    "print(\"1 vs R\")\n",
    "p1r = permutation_test(c1,cr)\n",
    "clear_output()\n",
    "print(p12, p13, p23, p1r)\n",
    "print(\"1 vs P\")\n",
    "p1p = permutation_test(c1,cp)\n",
    "print(p12, p13, p23, p1r, p1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eea053",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = [p12, p13, p23, p1r, p1p]\n",
    "p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"1 vs 2\", \"1 vs 3\", \"2 vs 3\", \"1 vs R\", \"1 vs P\"]\n",
    "reject, p_corr, alpha_sidak, alpha_bf  = multipletests(p_vals, method=\"fdr_bh\")\n",
    "for i in range(len(labels)):\n",
    "    print(\"%s (p = %.4f) || Reject: %s\" %(labels[i], p_corr[i], reject[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

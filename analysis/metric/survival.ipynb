{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(\"__file__\"))))\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from src.transformer.metrics import AUL, CorrectedMCC, CorrectedBAcc, CorrectedF1\n",
    "from src.analysis.metrics.cartesian import cartesian_jit\n",
    "\n",
    "from torchmetrics import MatthewsCorrCoef, F1Score, Accuracy\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "import time\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.colors as clr\n",
    "from matplotlib.ticker import MultipleLocator, LinearLocator, AutoMinorLocator\n",
    "plt.rcParams[\"grid.linestyle\"] =  \":\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.7\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "#sns.set_context(\"notebook\", font_scale=1.2)\n",
    "import scienceplots\n",
    "plt.style.use([\"nature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 6\n",
    "MEDIUM_SIZE = 6.4\n",
    "BIGGER_SIZE = 7\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "\n",
    "\n",
    "cmap = cmc.batlowS\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = \"4.02\"\n",
    "#v= \"6.3\"\n",
    "save_path = r\"../analysis/plots/%s/\" %v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_stats(path):\n",
    "    data = {}\n",
    "    with open(path + \"prb.npy\", \"rb\") as f:\n",
    "        data[\"prb\"] = np.load(f)\n",
    "    with open(path + \"trg.npy\", \"rb\") as f:\n",
    "        data[\"trg\"] = np.load(f)\n",
    "    with open(path + \"id.npy\", \"rb\") as f:\n",
    "        data[\"id\"] = np.load(f)\n",
    "    return data\n",
    "def metrics_parallel(metrics, preds, targs):\n",
    "    return metrics(preds, targs).numpy()\n",
    "def aul(prb_p, prb_a):\n",
    "    score = 0\n",
    "    for p in prb_p:\n",
    "        score += (p > prb_a).sum()\n",
    "    score += 0.5 * (p == prb_a).sum()\n",
    "    n_pos = float(prb_p.shape[0])\n",
    "    n = float(prb_a.shape[0])\n",
    "    return score/(n_pos*n)\n",
    "\n",
    "def return_aul(preds, targs):\n",
    "    preds_p = preds[targs==1]\n",
    "    return aul(preds_p, preds).item()\n",
    "def return_mcc(preds, targs):\n",
    "    metric = MatthewsCorrCoef(num_classes=2)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def return_acc(preds, targs):\n",
    "    metric = Accuracy(num_classes=2, average=\"macro\", multiclass=True)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def return_f1(preds, targs):\n",
    "    metric = F1Score(num_classes=2, average=\"macro\", multiclass=True)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def bootstrap_mcc(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.05, alpha: float = 0.025, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedMCC(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedMCC(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci /2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "def bootstrap_acc(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.05, alpha: float = 0.025, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedBAcc(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedBAcc(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci/2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "\n",
    "def bootstrap_f1(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.05, alpha: float = 0.025, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedF1(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedF1(alpha = alpha, beta = beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci/2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "def bootstrap_aul(preds, targs, seed: int = 2021, ci: float = 0.05, n_bootstraps: int = 1000, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i = resample(ids, stratify=targs, random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(return_aul)( preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    \n",
    "    return {\"mean\": return_aul(preds, targs), \"lower\": np.quantile(scores, ci /2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "\n",
    "def return_stats(path: str):\n",
    "    x  = load_stats(path)\n",
    "    start = time.time()\n",
    "    x[\"aul\"] = return_aul(preds = x[\"prb\"],  \n",
    "              targs = x[\"trg\"]) \n",
    "             # n_bootstraps=5000)\n",
    "    print(\"AUL is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"aul\"])\n",
    "    start = time.time()\n",
    "    x[\"mcc\"] = bootstrap_mcc(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n",
    "    print(\"MCC is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"mcc\"])\n",
    "    start = time.time()\n",
    "    x[\"acc\"] = bootstrap_acc(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n",
    "    print(\"ACC is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"acc\"])\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    x[\"f1\"] = bootstrap_f1(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n",
    "    print(\"F1 is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"f1\"])\n",
    "    return x\n",
    "\n",
    "def contains_in_sequence(sample, min_, max_):\n",
    "    \"\"\"Checks if sequence contains tokens in range [min_, max_]\"\"\"\n",
    "    return np.where((sample >= min_) & (sample <=max_))[0].shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rnn\"][\"prb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data[\"l2v\"] = return_stats(r\"...\\\\predictions\\\\v15\\\\cls\\\\eos_l2v\\\\%s\\\\\"%v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rnn\"] = return_stats(r\"...\\\\predictions\\\\v15\\\\cls\\\\eos_rnn\\\\1.0\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"nn\"] = return_stats(r\"...\\\\predictions\\\\v15\\\\tcls\\\\eos_tab\\\\1.0\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"logistic\"] = return_stats(r\"...\\\\predictions\\\\v15\\\\tcls\\\\eos_tab\\\\3.1\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"table\"] = return_stats(r\"...\\\\predictions\\\\v15\\\\tcls\\\\eos_tab\\\\3.2\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_baselines = True\n",
    "if simple_baselines:\n",
    "    np.random.seed(0)\n",
    "    data[\"rnd\"] = {\"prb\": np.random.uniform(size=data[\"rnn\"][\"trg\"].shape[0]),\n",
    "               \"trg\": data[\"rnn\"][\"trg\"]}\n",
    "    data[\"rnd\"][\"aul\"] = return_aul(preds = data[\"rnd\"][\"prb\"],  \n",
    "                               targs = data[\"rnd\"][\"trg\"])\n",
    "    data[\"rnd\"][\"mcc\"] = bootstrap_mcc(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n",
    "    data[\"rnd\"][\"acc\"] = bootstrap_acc(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n",
    "    data[\"rnd\"][\"f1\"] = bootstrap_f1(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,\n",
    "              alpha = 0.025,\n",
    "              beta=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data[\"mjr\"] = {\"prb\": np.random.uniform(high=0.5, size=data[\"rnn\"][\"trg\"].shape[0]),\n",
    "               \"trg\": data[\"rnn\"][\"trg\"]}\n",
    "data[\"mjr\"][\"aul\"] = return_aul(preds = data[\"mjr\"][\"prb\"],  \n",
    "                               targs = data[\"mjr\"][\"trg\"])\n",
    "data[\"mjr\"][\"mcc\"] = {\"mean\": return_mcc(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}\n",
    "data[\"mjr\"][\"acc\"] = {\"mean\": return_acc(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}\n",
    "data[\"mjr\"][\"f1\"] = {\"mean\": return_f1(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Error() \n",
    "    with open(save_path + \"metric.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data,f)\n",
    "except:\n",
    "    with open(save_path + \"metric.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUL\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"aul\"][\"mean\"], \n",
    "                                           data[key][\"aul\"][\"lower\"], \n",
    "                                           data[key][\"aul\"][\"upper\"]))\n",
    "print(\"MCC\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"mcc\"][\"mean\"], \n",
    "                                           data[key][\"mcc\"][\"lower\"], \n",
    "                                           data[key][\"mcc\"][\"upper\"]))\n",
    "print(\"ACC\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"acc\"][\"mean\"], \n",
    "                                           data[key][\"acc\"][\"lower\"], \n",
    "                                           data[key][\"acc\"][\"upper\"]))\n",
    "print(\"F1\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"f1\"][\"mean\"], \n",
    "                                           data[key][\"f1\"][\"lower\"], \n",
    "                                           data[key][\"f1\"][\"upper\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = list()\n",
    "quantiles = list()\n",
    "for key in data.keys():\n",
    "    if key == \"mjr\":\n",
    "        mean.append(0)\n",
    "        quantiles.append([0, 0])\n",
    "    else:\n",
    "        mean.append(data[key][\"mcc\"][\"mean\"])\n",
    "        quantiles.append([np.abs(mean[-1] - data[key][\"mcc\"][\"lower\"]),  np.abs(mean[-1] - data[key][\"mcc\"][\"upper\"])])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,7))\n",
    "plt.bar(x = data.keys(), height = mean, width=0.5,\n",
    "        yerr=np.array(quantiles).T, capsize=4, \n",
    "        edgecolor=\"none\", facecolor=\"silver\", ecolor=\"black\")\n",
    "\n",
    "# plt.errorbar(x = list(data.keys()), y = mean, yerr = np.array(quantiles).T, fmt=\"o\",\n",
    "#                      capsize=5, ecolor=\"dimgray\", ms=3.5,\n",
    "#                      elinewidth=2, mfc=\"black\", mec=\"black\")\n",
    "ax.set_ylabel(\"MCC Score\")\n",
    "ax.set_xlabel(\"Model\")\n",
    "#ax.set_title(\"Mortality Prediction: Corrected Matthews Correlation Coefficient with 95%-CI\")\n",
    "ax.set_ylim( -0.1 , 0.5)\n",
    "ax.axhline(0.0, color=\"gray\", linewidth=0.5, linestyle= \":\")\n",
    "#ax.tick_params(which=\"both\", width=2, length =2)\n",
    "ax.tick_params(axis= \"y\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"y\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"x\", which=\"both\", width=0, length =0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "sns.despine()\n",
    "plt.savefig(save_path + \"mcc_mortality.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = list()\n",
    "quantiles = list()\n",
    "for key in data.keys():\n",
    "    mean.append(data[key][\"acc\"][\"mean\"])\n",
    "    quantiles.append([np.abs(mean[-1] - data[key][\"acc\"][\"lower\"]),  np.abs(mean[-1] - data[key][\"acc\"][\"upper\"])])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,7))\n",
    "plt.bar(x = data.keys(), height = mean, width=0.5,\n",
    "        yerr=np.array(quantiles).T, capsize=4, \n",
    "        edgecolor=\"none\", facecolor=\"silver\", ecolor=\"black\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_title(\"Mortality Prediction: Corrected Accuracy with 95%-CI\")\n",
    "ax.tick_params(axis= \"y\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"y\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"x\", which=\"both\", width=0, length =0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "sns.despine()\n",
    "plt.savefig(save_path + \"acc_mortality.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = list()\n",
    "quantiles = list()\n",
    "for key in data.keys():\n",
    "    mean.append(data[key][\"f1\"][\"mean\"])\n",
    "    quantiles.append([np.abs(mean[-1] - data[key][\"f1\"][\"lower\"]),  np.abs(mean[-1] - data[key][\"f1\"][\"upper\"])])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,7))\n",
    "plt.bar(x = data.keys(), height = mean, width=0.5,\n",
    "        yerr=np.array(quantiles).T, capsize=4, \n",
    "        edgecolor=\"none\", facecolor=\"silver\", ecolor=\"black\")\n",
    "ax.set_ylabel(\"F1-Score\")\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_title(\"Mortality Prediction: Corrected F1-Score with 95%-CI\")\n",
    "ax.tick_params(axis= \"y\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"y\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"x\", which=\"both\", width=0, length =0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "sns.despine()\n",
    "plt.savefig(save_path + \"f1_mortality.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = list()\n",
    "quantiles = list()\n",
    "for key in data.keys():\n",
    "    mean.append(data[key][\"aul\"][\"mean\"])\n",
    "    quantiles.append([np.abs(mean[-1] - data[key][\"aul\"][\"lower\"]),  np.abs(mean[-1] - data[key][\"aul\"][\"upper\"])])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,7))\n",
    "plt.bar(x = data.keys(), height = mean,  width=0.5,\n",
    "        yerr=np.array(quantiles).T, capsize=4, \n",
    "        edgecolor=\"none\", facecolor=\"silver\", ecolor=\"black\")\n",
    "ax.set_ylabel(\"AUL Score\")\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_title(\"Mortality Prediction: Area Under the Lift with 95%-CI\")\n",
    "ax.tick_params(axis= \"y\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"y\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "ax.tick_params(axis= \"x\", which=\"both\", width=0, length =0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(save_path + \"aul_mortality.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Breakdown by Unitary Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1951, 1956, 1961, 1966, 1971, 1976, 1982]\n",
    "period = [(pd.to_datetime(\"01/01/%s\" %a), pd.to_datetime(\"31/12/%s\" %b)) for a, b in zip(years[:-1], years[1:])]\n",
    "period.reverse()\n",
    "def discrete_age(x):\n",
    "    for i, p in enumerate(period):\n",
    "        if (x >= p[0]) & (x <= p[1]):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"...\\\\predictions\\\\v15\\\\cls\\\\eos_l2v\\\\%s\\\\\" %v + \"seqlen.pkl\", \"rb\") as f:\n",
    "    counts = pickle.load(f)\n",
    "    counts = pd.DataFrame.from_dict(counts, orient=\"index\")\n",
    "    counts.index = counts.index.rename(\"PERSON_ID\")\n",
    "    counts = counts.rename(columns={0: \"SEQLEN\"})\n",
    "    counts[\"SEQLEN\"] = counts[\"SEQLEN\"].apply(lambda x: np.minimum(x, 2560))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"...\\\\predictions\\\\v15\\\\cls\\\\eos_l2v\\\\%s\\\\\" %v + \"has_health.pkl\", \"rb\") as f:\n",
    "    has_health = pickle.load(f)\n",
    "    has_health = pd.DataFrame.from_dict(has_health, orient=\"index\")\n",
    "    has_health.index = has_health.index.rename(\"PERSON_ID\")\n",
    "    has_health = has_health.rename(columns={0: \"HAS_HEALTH\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = pd.read_csv(\".../processed/populations/survival/population/result.csv\").set_index(\"PERSON_ID\")\n",
    "ppl[\"EVENT_FINAL_DATE\"] = pd.to_datetime(ppl[\"EVENT_FINAL_DATE\"], format=\"%Y-%m-%d\")\n",
    "result = pd.DataFrame({\"PERSON_ID\": data[\"l2v\"][\"id\"].astype(int),\n",
    "                        \"PRED\": data[\"l2v\"][\"prb\"]}).set_index(\"PERSON_ID\")\n",
    "result = result.join(ppl, how=\"left\").dropna()\n",
    "result = result.join(counts, how=\"left\").dropna()\n",
    "result = result.join(has_health, how=\"left\").dropna()\n",
    "result[\"HAS_HEALTH_RAW\"] = result[\"HAS_HEALTH\"].values\n",
    "hh_q = np.quantile(result[\"HAS_HEALTH\"].values, [0, 0.25, 0.5, 0.75, 0.9,  1.])\n",
    "hh_q[1] = 1\n",
    "result[\"HAS_HEALTH\"] = pd.cut(result[\"HAS_HEALTH\"], bins = hh_q,\n",
    "                               include_lowest=True, labels=False)\n",
    "ec_q = np.quantile(result[\"SEQLEN\"].values, [0, 0.33, 0.66, 1.])\n",
    "result[\"SEQLEN\"] = pd.cut(result[\"SEQLEN\"], bins = ec_q,\n",
    "                               include_lowest=True, labels=False)\n",
    "result[\"BIRTHDAY\"] = pd.to_datetime(result[\"BIRTHDAY\"], format=\"%Y-%m-%d\")\n",
    "result[\"AGE_GROUP\"] = result[\"BIRTHDAY\"].apply(lambda x: discrete_age(x))\n",
    "result[\"UNLABELED\"] = result.apply(lambda x: (x[\"TARGET\"] == 0) & (x[\"EVENT_FINAL_DATE\"] < pd.to_datetime(\"2020-12-31\", format=\"%Y-%m-%d\")), axis = 1)\n",
    "result[\"YEAR\"] = result[\"EVENT_FINAL_DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = result.groupby([\"AGE_GROUP\"])[\"HAS_HEALTH_RAW\"].agg([\"median\", mad])\n",
    "labels_ = [\"(34,39]\", \"(39, 44]\", \"(44, 49]\", \"(49, 54]\", \"(54, 59]\",  \"(59, 64]\"]\n",
    "figsize =(max_width_in_inches, max_width_in_inches/2)\n",
    "fig = plt.figure(figsize= figsize)\n",
    "plt.bar(labels_, df_[\"median\"], yerr= df_[\"median_abs_deviation\"], capsize=5, width=0.5, label = \"median with +/- one Median Abs. Dev.\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Median Number of Health Records\")\n",
    "plt.title(\"Number of Health Records per Age Group\")\n",
    "plt.tick_params(which=\"both\", right=False, top=False)\n",
    "plt.tick_params(which=\"minor\", bottom=False)\n",
    "\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"health_per_age.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_simple(x, n_samples = 1000):\n",
    "    N = x.shape[0]\n",
    "    out = list()\n",
    "    for i in range(n_samples):\n",
    "        _id = np.random.choice(N, size=N, replace=True)\n",
    "        tp = x[_id].sum()\n",
    "        out.append(tp/N)\n",
    "    return out, N, \n",
    "        \n",
    "        \n",
    "py_label = [2016, 2017, 2018, 2019]\n",
    "py_recall = list()\n",
    "py_n_tp = list()\n",
    "py_n_total = list()\n",
    "for i in py_label:\n",
    "    r = result[(result[\"YEAR\"]== (i)) & (result[\"TARGET\"] == 1)]\n",
    "    y_hat = np.array((r[\"PRED\"].values > 0.5)).astype(int)\n",
    "    _recall, _n = bootstrap_simple(y_hat)\n",
    "    py_recall.append((np.mean(_recall), np.std(_recall)))\n",
    "    py_n_tp.append(y_hat.sum())\n",
    "    py_n_total.append(_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width_in_mm = 180\n",
    "max_width_in_inches = max_width_in_mm / 25.4\n",
    "fig, ax = plt.subplots(1,2, figsize=(max_width_in_inches, max_width_in_inches/2))\n",
    "mu = [i for i, _ in py_recall]\n",
    "std = [i for _, i in py_recall]\n",
    "ax[0].bar(x=py_label, height=mu, xerr=std, width=0.5, label=\"recall value\")\n",
    "ax[0].set_xlabel(\"Year of death\")\n",
    "ax[0].set_ylabel(\"Fraction of correctly identified deceased people\")\n",
    "ax[0].set_title(\"Recall for deceased people\")\n",
    "ax[0].set_ylim([0, 1.])\n",
    "ax[0].tick_params(axis= \"x\", which=\"major\", width= 1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[0].tick_params(axis= \"y\", which=\"minor\", width= 1, length = 3, direction=\"out\", color=\"gray\")\n",
    "ax[0].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax[0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax[0].xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax[0].legend() \n",
    "ax[0].tick_params(which=\"both\", top=False, right=False)\n",
    "ax[0].tick_params(which=\"minor\", bottom=False)\n",
    "\n",
    "\n",
    "ax[1].bar(x=[i-0.17 for i in py_label], height=py_n_total, width=0.3, label=\"all predicted deceased\")\n",
    "ax[1].bar(x=[i+ 0.17 for i in py_label], height=py_n_tp, width=0.3, label = \"correctly predicted deceased\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Year of death\")\n",
    "ax[1].set_ylabel(\"Fraction of correctly identified deceased people\")\n",
    "ax[1].set_title(\"Predictions for deceased people\")\n",
    "# ax[1].set_ylim([0, 1.])\n",
    "ax[1].tick_params(axis= \"x\", which=\"major\", width= 1, length = 6, direction=\"out\", color=\"gray\")\n",
    "ax[1].tick_params(axis= \"y\", which=\"minor\", width= 1, length = 3, direction=\"out\", color=\"gray\")\n",
    "ax[1].xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax[1].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax[1].tick_params(which=\"both\", top=False, right=False)\n",
    "ax[1].tick_params(which=\"minor\", bottom=False)\n",
    "ax[1].legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"yearly_mortality_performance.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = result.copy()[[\"TARGET\", \"PRED\", \"RES_ORIGIN\", \"GENDER\", \"SEQLEN\", \"HAS_HEALTH\", \"AGE_GROUP\", \"UNLABELED\"]]\n",
    "dfm[\"TARGET\"] = dfm[\"TARGET\"].astype(bool)\n",
    "dfm[\"PRED\"] = (dfm[\"PRED\"] >=0.5).astype(bool)\n",
    "dfm = dfm.rename(columns={\"TARGET\": \"true_label (deceased)\", \n",
    "                    \"RES_ORIGIN\": \"res_status\",\n",
    "                    \"PRED\": \"l2v_pred\", \n",
    "                    \"GENDER\": \"sex\",\n",
    "                    \"SEQLEN\": \"num_events\",\n",
    "                    \"HAS_HEALTH\": \"num_health_events\",\n",
    "                    \"AGE_GROUP\": \"age\",\n",
    "                    \"UNLABELED\": \"unlabeled\" })\n",
    "dfm[\"age\"] = dfm[\"age\"].replace({0:'(34,39]', 1:'(39, 44]', 2:'(44, 49]', 3:'(49, 54]', 4:'(54, 59]', 5:'(59, 64]'})\n",
    "dfm[\"num_events\"] = dfm[\"num_events\"].replace({0:'[48, 921)', 1:'[921, 1176)', 2:'[1176, 2560]'})\n",
    "dfm[\"num_health_events\"] = dfm[\"num_health_events\"].replace({0:'[0]', 1:'[1,5)', 2:'[5,11)', 3: '[11,19)', 4:'>18'})\n",
    "np.random.seed(42)\n",
    "dfm = dfm.sample(frac=1).reset_index(drop=True)\n",
    "dfm.to_csv(save_path + \"l2v_mortality_predictions_with_groups.csv\")\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\"male\": result[\"GENDER\"] == \"M\",\n",
    "          \"female\": result[\"GENDER\"] == \"F\",\n",
    "          \"(34,39]\": result[\"AGE_GROUP\"] == 0,\n",
    "          \"(39, 44]\": result[\"AGE_GROUP\"] == 1,\n",
    "          \"(44, 49]\": result[\"AGE_GROUP\"] == 2,\n",
    "          \"(49, 54]\": result[\"AGE_GROUP\"] == 3,\n",
    "          \"(54, 59]\": result[\"AGE_GROUP\"] == 4,\n",
    "          \"(59, 64]\": result[\"AGE_GROUP\"] == 5,\n",
    "          \"DK\": result[\"RES_ORIGIN\"] == \"DK\",\n",
    "          \"NON-DK\": result[\"RES_ORIGIN\"] == \"NON_DK\",\n",
    "          \"[48, 921)\": result[\"SEQLEN\"] == 0,\n",
    "          \"[921, 1176)\": result[\"SEQLEN\"] == 1,\n",
    "          \"[1176, 2560]\": result[\"SEQLEN\"] == 2,\n",
    "          \"[0]\": result[\"HAS_HEALTH\"] == 0,\n",
    "          \"[1,5)\": result[\"HAS_HEALTH\"] == 1,\n",
    "          \"[5,11)\": result[\"HAS_HEALTH\"] == 2,\n",
    "          \"[11,19)\": result[\"HAS_HEALTH\"] == 3,\n",
    "          \">=19\": result[\"HAS_HEALTH\"] == 4\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = result[\"HAS_HEALTH\"] == 4\n",
    "preds = result[\"PRED\"].values\n",
    "targs = result[\"TARGET\"].values\n",
    "alpha = result[\"UNLABELED\"].mean()\n",
    "metric = CorrectedMCC(alpha = 0.025, beta= 1., threshold = 0.5, average=\"micro\")\n",
    "metric(torch.Tensor(preds),torch.IntTensor(targs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CorrectedMCC(alpha = 0.025, beta= 1., threshold = 0.5, average=\"micro\")\n",
    "metric(torch.Tensor(preds),torch.IntTensor(targs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_mcc = {}\n",
    "unitary_prb = {}\n",
    "unitary_cnt = {}\n",
    "\n",
    "for k, condition in groups.items():\n",
    "    preds = result[condition][\"PRED\"].values\n",
    "    targs = result[condition][\"TARGET\"].values\n",
    "    unitary_mcc[k] = bootstrap_mcc(torch.from_numpy(preds).float(), torch.from_numpy(targs).long())\n",
    "    unitary_prb[k] = {\"median\": np.median(preds), \"mad\": mad(preds)}\n",
    "    unitary_cnt[k] = {\"total\": preds.shape[0], \"positive\": np.sum(targs), \"unlabeled\": result[condition][\"UNLABELED\"].values.sum()}\n",
    "    print(\"Done:\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_stats(labels, prb_dict, count_dict,  mcc_dict, title:str, figsize=(10,10)):\n",
    "    mu, var, err = [], [], []\n",
    "    padding = 0.5\n",
    "\n",
    "    for label in labels:\n",
    "        mu.append(prb_dict[label][\"median\"])\n",
    "        var.append(prb_dict[label][\"mad\"])\n",
    "        err.append([mu[-1] - var[-1], mu[-1] + var[-1]])\n",
    "    \n",
    "    fig, ax = plt.subplots(2,2, figsize=figsize)\n",
    "\n",
    "    #### MEDIAN PRB\n",
    "    ax[0,0].errorbar(y = labels, x = mu, xerr = var, fmt=\"o\",\n",
    "                     capsize=5, ecolor=\"dimgray\", ms=3.5,\n",
    "                     elinewidth=2, mfc=\"black\", mec=\"black\", label=r\"median with +/- one Median Abs. Dev.\")\n",
    "    \n",
    "    ax[0,0].set_xlabel(\"Median Probability of Death\")\n",
    "    ax[0,0].set_ylabel(\"%s\" %title)\n",
    "    ax[0,0].set_title(\"Median Probability of Death per %s\" %title)\n",
    "\n",
    "    ax[0,0].tick_params(axis= \"x\", which=\"major\", width= 1, length = 6, direction=\"out\", color=\"gray\")\n",
    "    ax[0,0].tick_params(axis= \"x\", which=\"minor\", width= 1, length = 3, direction=\"out\", color=\"gray\")\n",
    "    ax[0,0].tick_params(axis= \"y\", which=\"both\", width=0, length =0)\n",
    "\n",
    "    ax[0,0].xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax[0,0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    ax[0,0].set_ylim(-padding, len(labels) - 1 + padding)\n",
    "    ax[0,0].set_xlim([0, 1.])\n",
    "    ax[0,0].tick_params(which=\"both\", top=False, right=False)\n",
    "    ax[0,0].legend()\n",
    "    #### POSITIVE COUNT\n",
    "    count = list()\n",
    "    for label in labels:\n",
    "        count.append(count_dict[label][\"positive\"])\n",
    "\n",
    "    ax[0,1].barh(y = labels, height = 0.5,  \n",
    "        width=count,  edgecolor=\"none\", facecolor=\"silver\", label=\"Number of Deceased\")\n",
    "    ax[0,1].set_xlabel(\"Number of Deceased\")\n",
    "    ax[0,1].set_ylabel(\"%s\" %title)\n",
    "    ax[0,1].set_title(\"Number of Deceased People per %s\" %title)\n",
    "\n",
    "    ax[0,1].tick_params(axis= \"x\", which=\"major\", width= 1, length = 6, direction=\"out\", color=\"gray\")\n",
    "    ax[0,1].tick_params(axis= \"x\", which=\"minor\", width= 1, length = 3, direction=\"out\", color=\"gray\")\n",
    "    ax[0,1].tick_params(axis= \"y\", which=\"both\", width=0, length =0)\n",
    "\n",
    "    ax[0,1].xaxis.set_major_locator(MultipleLocator(500))\n",
    "    ax[0,1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    ax[0,1].legend()\n",
    "    ax[0,1].tick_params(which=\"both\", top=False, right=False)\n",
    "\n",
    "\n",
    "    ### POPULATION COUNTS\n",
    "    count = list()\n",
    "    for label in labels:\n",
    "        count.append(count_dict[label][\"total\"])\n",
    "    ax[1,0].barh(y = labels, height = 0.5, label = \"alive\",  width=count, facecolor=\"silver\", edgecolor=\"none\")\n",
    "    count = list()\n",
    "    for label in labels:\n",
    "        count.append(count_dict[label][\"positive\"] + count_dict[label][\"unlabeled\"])\n",
    "    \n",
    "    ax[1,0].barh(y = labels, height = 0.5, label= \"unlabeled\",  width=count, facecolor=\"orange\", edgecolor=\"none\")\n",
    "    count = list()\n",
    "    for label in labels:\n",
    "        count.append(count_dict[label][\"positive\"])\n",
    "    ax[1,0].barh(y = labels, height = 0.5, label= \"deceased\",  width=count, facecolor=\"dimgray\", edgecolor=\"none\")\n",
    "\n",
    "\n",
    "    ax[1,0].set_xlabel('Number of People')\n",
    "    ax[1,0].set_ylabel(\"%s\" %title)\n",
    "    ax[1,0].set_title(\"Number of People (stacked) per %s\" %title)\n",
    "    ax[1,0].tick_params(axis= \"x\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "    ax[1,0].tick_params(axis= \"x\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "    ax[1,0].tick_params(axis= \"y\", which=\"both\", width=0, length =0)\n",
    "    xlim = np.max([ax[1,0].get_xlim()[1], 10100])\n",
    "    ax[1,0].set_xlim([0, xlim])\n",
    "    if xlim < 35000:\n",
    "        ax[1,0].xaxis.set_major_locator(MultipleLocator(5000))\n",
    "    else:\n",
    "        ax[1,0].xaxis.set_major_locator(MultipleLocator(15000))\n",
    "\n",
    "    ax[1,0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    ax[1,0].legend()\n",
    "    ax[1,0].tick_params(which=\"both\", top=False, right=False)\n",
    "\n",
    "    mu, var, err = [], [], []\n",
    "\n",
    "    for label in labels:\n",
    "        mu.append(mcc_dict[label][\"mean\"])\n",
    "        var.append(mcc_dict[label][\"upper\"])\n",
    "        err.append([np.abs(mu[-1] - mcc_dict[label][\"lower\"]), np.abs(mu[-1] - mcc_dict[label][\"upper\"])])\n",
    "        \n",
    "\n",
    "    ax[1,1].errorbar(y = labels,  \n",
    "        xerr= np.array(err).T, x= mu, fmt=\"o\",\n",
    "                     capsize=5, ecolor=\"dimgray\", ms=3.5,\n",
    "                     elinewidth=2, mfc=\"black\", mec=\"black\", label=\"mean with 95\\%-CI (bootstrap)\")\n",
    "    ax[1,1].set_xlabel(\"MCC Score\")\n",
    "    ax[1,1].set_ylabel(\"%s\" %title)\n",
    "    ax[1,1].set_title(\"Corrected MCC per %s\" %title)\n",
    "    xlim = np.max([np.max(var) + 0.05, 0.8])\n",
    "    ax[1,1].set_xlim([-0.1, xlim])\n",
    "    ax[1,1].set_ylim([-padding, len(labels)-1+padding])\n",
    "    ax[1,1].axvline(0.0, color=\"gray\", linewidth=0.5, linestyle= \":\", label=\"center line\")\n",
    "    ax[1,1].axvline(0.413, color=\"blue\", linewidth=1, linestyle= \":\", label=\"global mean\")\n",
    "\n",
    "\n",
    "    ax[1,1].tick_params(axis= \"x\", which=\"major\", width=1, length = 6, direction=\"out\", color=\"gray\")\n",
    "    ax[1,1].tick_params(axis= \"x\", which=\"minor\", width=1, length =3, direction=\"out\", color=\"gray\")\n",
    "    ax[1,1].tick_params(axis= \"y\", which=\"both\", width=0, length =0)\n",
    "\n",
    "    ax[1,1].xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax[1,1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    ax[1,1].legend()\n",
    "    ax[1,1].tick_params(which=\"both\", top=False, right=False)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width_in_mm = 180\n",
    "max_width_in_inches = max_width_in_mm / 25.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['[0]', '[1,5)', '[5,11)', '[11,19)', '>=19']\n",
    "group_title = \"Health Group\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches / 2)\n",
    "return_stats(labels, unitary_prb, unitary_cnt, unitary_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_health_events.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ '[48, 921)', '[921, 1176)', '[1176, 2560]']\n",
    "group_title = \"Sequence Len Group\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches / 2.5)\n",
    "return_stats(labels, unitary_prb, unitary_cnt, unitary_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_seqlen.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['(34,39]', '(39, 44]', '(44, 49]', '(49, 54]', '(54, 59]', '(59, 64]']\n",
    "group_title = \"Age Group\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches / 1.3)\n",
    "return_stats(labels, unitary_prb, unitary_cnt, unitary_mcc, group_title, figsize=figsize)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_age.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"male\", \"female\", \"DK\", \"NON-DK\"]\n",
    "group_title = \"Unitary (Subset) Groups\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches / 2)\n",
    "return_stats(labels, unitary_prb, unitary_cnt, unitary_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_unitary.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['male', 'female', '(34,39]', '(39, 44]', '(44, 49]', '(49, 54]', '(54, 59]', '(59, 64]', 'DK', 'NON-DK']\n",
    "group_title = \"Unitary (All) Groups\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches)\n",
    "return_stats(labels, unitary_prb, unitary_cnt, unitary_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_unitary_full.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_groups = dict()\n",
    "\n",
    "for l1 in ['(34,39]', '(39, 44]', '(44, 49]', '(49, 54]', '(54, 59]', '(59, 64]']:\n",
    "    for l2 in [\"male\", \"female\"]:\n",
    "        intersect_groups[\" \".join([l1,l2])] = (groups[l1]) & (groups[l2])\n",
    "\n",
    "intersec_mcc = {}\n",
    "intersec_prb = {}\n",
    "intersec_cnt = {}\n",
    "\n",
    "for k, condition in intersect_groups.items():\n",
    "    preds = result[condition][\"PRED\"].values\n",
    "    targs = result[condition][\"TARGET\"].values\n",
    "    intersec_mcc[k] = bootstrap_mcc(torch.from_numpy(preds).float(), torch.from_numpy(targs).long())\n",
    "    intersec_prb[k] = {\"median\": np.median(preds), \"mad\": mad(preds)}\n",
    "    intersec_cnt[k] = {\"total\": preds.shape[0], \"positive\": np.sum(targs), \"unlabeled\": result[condition][\"UNLABELED\"].values.sum()}\n",
    "    print(\"Done:\", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(intersect_groups.keys())\n",
    "group_title = \"Intersectional (All) Groups\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches)\n",
    "return_stats(labels, intersec_prb, intersec_cnt, intersec_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_intersect_age_sex.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_groups = dict()\n",
    "\n",
    "for l1 in ['[0]', '[1,5)', '[5,11)', '[11,19)', '>=19']:\n",
    "    for l2 in [\"male\", \"female\"]:\n",
    "        intersect_groups[\" \".join([l1,l2])] = (groups[l1]) & (groups[l2])\n",
    "\n",
    "intersec_mcc = {}\n",
    "intersec_prb = {}\n",
    "intersec_cnt = {}\n",
    "\n",
    "for k, condition in intersect_groups.items():\n",
    "    preds = result[condition][\"PRED\"].values\n",
    "    targs = result[condition][\"TARGET\"].values\n",
    "    intersec_mcc[k] = bootstrap_mcc(torch.from_numpy(preds).float(), torch.from_numpy(targs).long())\n",
    "    intersec_prb[k] = {\"median\": np.median(preds), \"mad\": mad(preds)}\n",
    "    intersec_cnt[k] = {\"total\": preds.shape[0], \"positive\": np.sum(targs), \"unlabeled\": result[condition][\"UNLABELED\"].values.sum()}\n",
    "    print(\"Done:\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(intersect_groups.keys())\n",
    "group_title = \"Intersectional (Subset) Groups\"\n",
    "figsize=(max_width_in_inches, max_width_in_inches)\n",
    "return_stats(labels, intersec_prb, intersec_cnt, intersec_mcc, group_title, figsize=figsize)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_intersect_sex_health.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_groups = dict()\n",
    "\n",
    "for l1 in ['[48, 921)', '[921, 1176)', '[1176, 2560]']:\n",
    "    for l2 in [\"male\", \"female\"]:\n",
    "        intersect_groups[\" \".join([l1,l2])] = (groups[l1]) & (groups[l2])\n",
    "\n",
    "intersec_mcc = {}\n",
    "intersec_prb = {}\n",
    "intersec_cnt = {}\n",
    "\n",
    "for k, condition in intersect_groups.items():\n",
    "    preds = result[condition][\"PRED\"].values\n",
    "    targs = result[condition][\"TARGET\"].values\n",
    "    intersec_mcc[k] = bootstrap_mcc(torch.from_numpy(preds).float(), torch.from_numpy(targs).long())\n",
    "    intersec_prb[k] = {\"median\": np.median(preds), \"mad\": mad(preds)}\n",
    "    intersec_cnt[k] = {\"total\": preds.shape[0], \"positive\": np.sum(targs), \"unlabeled\": result[condition][\"UNLABELED\"].values.sum()}\n",
    "    print(\"Done:\", k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(intersect_groups.keys())\n",
    "group_title = \"Intersectional (Subset) Groups\"\n",
    "return_stats(labels, intersec_prb, intersec_cnt, intersec_mcc, group_title, figsize=(11,7))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_intersect_sex_length.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age vs Number of Health Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGE vs Health Records\n",
    "intersect_groups = dict()\n",
    "\n",
    "for l1 in ['(34,39]', '(39, 44]', '(44, 49]', '(49, 54]', '(54, 59]', '(59, 64]']:\n",
    "    for l2 in  ['[0]', '[1,5)', '[5,11)', '[11,19)', '>=19']:\n",
    "        intersect_groups[\" \".join([l1,l2])] = (groups[l1]) & (groups[l2])\n",
    "\n",
    "intersec_mcc = {}\n",
    "intersec_prb = {}\n",
    "intersec_cnt = {}\n",
    "\n",
    "for k, condition in intersect_groups.items():\n",
    "    preds = result[condition][\"PRED\"].values\n",
    "    targs = result[condition][\"TARGET\"].values\n",
    "    intersec_mcc[k] = bootstrap_mcc(torch.from_numpy(preds).float(), torch.from_numpy(targs).long())\n",
    "    intersec_prb[k] = {\"median\": np.median(preds), \"mad\": mad(preds)}\n",
    "    intersec_cnt[k] = {\"total\": preds.shape[0], \"positive\": np.sum(targs), \"unlabeled\": result[condition][\"UNLABELED\"].values.sum()}\n",
    "    print(\"Done:\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(intersect_groups.keys())\n",
    "group_title = \"Intersectional (Age vs Health Events) Groups\"\n",
    "return_stats(labels, intersec_prb, intersec_cnt, intersec_mcc, group_title, figsize=(11,7))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"mortality_intersect_age_health.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

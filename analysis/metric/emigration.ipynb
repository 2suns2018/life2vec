{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(\"__file__\"))))\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from src.transformer.metrics import AUL, CorrectedMCC, CorrectedBAcc, CorrectedF1\n",
    "from src.analysis.metrics.cartesian import cartesian_jit\n",
    "\n",
    "from torchmetrics import MatthewsCorrCoef, F1Score, Accuracy\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "import time\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.colors as clr\n",
    "from matplotlib.ticker import MultipleLocator, LinearLocator, AutoMinorLocator\n",
    "plt.rcParams[\"grid.linestyle\"] =  \":\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.7\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Helvetica\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "This notebook is used to evaluate the *Emigration* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQBiYXRsb3dTIGNvbG9ybWFwdnAoIwAAABx0RVh0RGVzY3JpcHRpb24AYmF0bG93UyBjb2xvcm1hcNFemVoAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ6zWY90AAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuNC4yLCBodHRwczovL21hdHBsb3RsaWIub3JngnD8+gAAA2lJREFUeJzt1suLlXUcx/HfmGM0mpEX1Kaki12I6eJlKsOCCIkKclFkVpYE4SLCwJCCXCRBbsI2QlMLE8KBCFpYthiGIjOMzC7WBNlQEymSUjOSVObM9Ad8/Av6vl7LN4dzDr/nOc/5dHQsWDPZzuKf3Tujbd1zc7QdwzdE++q26dEeHRqJ9snXc6KdeOb+aHuHt0R78OProrXW2tGnN0abPDYQ7da9n0X7/tOp0bavORht39jsaJu6L4jW8+rMaKe23hWttdYm5q+M9v7+fO3CzlnR9v55IlrfT4uj3bPgh2g7Dlwb7cjqi6PN68vr11pri5edinb4eJ7FyLonoq0dfDHatsvnRXvu5yPRjv6dZ/vesluiTZmW59Vaa/Pf2h9t/ZJD0U6emRbt4bn5ft2dF0Wbfd6l0a7Y83u0N5d/GW10/N/8kNbak28viXZOV0e0O3t/i9b/QH+0ntc3RNt41YFoz3/YG+34hkeiXbZrV7TWWnvqmi+iPduzOdrErKXROk7nmS19Z1u0oQ/yUdY5Y0q0G+84He2Nq0ejtdbavHPzt7D6uz+iffvrhdHOnzkR7bXr8x4bGM3veOjkgmi7b38o2rvDL0drrbWxM/nZj/fmtenpfyXawRV5L4+P/xVt7dDhaCvn5HNiU38+iyZOn/Vvp7209ptoGxatjzbZvSra3M0vRNt+d97L+8byWvXtvCRa76o8wx9HuqK11tqxdSui3TQ4GG3LoqFojw3k+Xx07y/R7vt8YbR9y/O6dE3NZ+OM6VdGa621vPMAgP89AwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKCg/wBqcpWrcNIAqQAAAABJRU5ErkJggg==",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>batlowS</strong> </div><div class=\"cmap\"><img alt=\"batlowS colormap\" title=\"batlowS\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQBiYXRsb3dTIGNvbG9ybWFwdnAoIwAAABx0RVh0RGVzY3JpcHRpb24AYmF0bG93UyBjb2xvcm1hcNFemVoAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ6zWY90AAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuNC4yLCBodHRwczovL21hdHBsb3RsaWIub3JngnD8+gAAA2lJREFUeJzt1suLlXUcx/HfmGM0mpEX1Kaki12I6eJlKsOCCIkKclFkVpYE4SLCwJCCXCRBbsI2QlMLE8KBCFpYthiGIjOMzC7WBNlQEymSUjOSVObM9Ad8/Av6vl7LN4dzDr/nOc/5dHQsWDPZzuKf3Tujbd1zc7QdwzdE++q26dEeHRqJ9snXc6KdeOb+aHuHt0R78OProrXW2tGnN0abPDYQ7da9n0X7/tOp0bavORht39jsaJu6L4jW8+rMaKe23hWttdYm5q+M9v7+fO3CzlnR9v55IlrfT4uj3bPgh2g7Dlwb7cjqi6PN68vr11pri5edinb4eJ7FyLonoq0dfDHatsvnRXvu5yPRjv6dZ/vesluiTZmW59Vaa/Pf2h9t/ZJD0U6emRbt4bn5ft2dF0Wbfd6l0a7Y83u0N5d/GW10/N/8kNbak28viXZOV0e0O3t/i9b/QH+0ntc3RNt41YFoz3/YG+34hkeiXbZrV7TWWnvqmi+iPduzOdrErKXROk7nmS19Z1u0oQ/yUdY5Y0q0G+84He2Nq0ejtdbavHPzt7D6uz+iffvrhdHOnzkR7bXr8x4bGM3veOjkgmi7b38o2rvDL0drrbWxM/nZj/fmtenpfyXawRV5L4+P/xVt7dDhaCvn5HNiU38+iyZOn/Vvp7209ptoGxatjzbZvSra3M0vRNt+d97L+8byWvXtvCRa76o8wx9HuqK11tqxdSui3TQ4GG3LoqFojw3k+Xx07y/R7vt8YbR9y/O6dE3NZ+OM6VdGa621vPMAgP89AwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKAgAwAACjIAAKCg/wBqcpWrcNIAqQAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#011959ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #011959ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#fba68cff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #fba68cff;\"></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x2a479dff1c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmap = cmc.batlowS\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= \"0.3\"\n",
    "save_path = r\"O:/projekter/PY000017_D/analysis/plots/em/%s/\" %v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_stats(path):\n",
    "    data = {}\n",
    "    with open(path + \"prb.npy\", \"rb\") as f:\n",
    "        data[\"prb\"] = np.load(f)\n",
    "    with open(path + \"trg.npy\", \"rb\") as f:\n",
    "        data[\"trg\"] = np.load(f)\n",
    "    with open(path + \"id.npy\", \"rb\") as f:\n",
    "        data[\"id\"] = np.load(f)\n",
    "    return data\n",
    "def metrics_parallel(metrics, preds, targs):\n",
    "    return metrics(preds, targs).numpy()\n",
    "def aul(prb_p, prb_a):\n",
    "    score = 0\n",
    "    for p in prb_p:\n",
    "        score += (p > prb_a).sum()\n",
    "    score += 0.5 * (p == prb_a).sum()\n",
    "    n_pos = float(prb_p.shape[0])\n",
    "    n = float(prb_a.shape[0])\n",
    "    return score/(n_pos*n)\n",
    "\n",
    "def return_aul(preds, targs):\n",
    "    preds_p = preds[targs==1]\n",
    "    return aul(preds_p, preds).item()\n",
    "def return_mcc(preds, targs):\n",
    "    metric = MatthewsCorrCoef(num_classes=2)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def return_acc(preds, targs):\n",
    "    metric = Accuracy(num_classes=2, average=\"macro\", multiclass=True)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def return_f1(preds, targs):\n",
    "    metric = F1Score(num_classes=2, average=\"macro\", multiclass=True)\n",
    "    return metric(preds, targs).numpy().item()\n",
    "\n",
    "def bootstrap_mcc(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.015, alpha: float = 0.01, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedMCC(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedMCC(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci /2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "def bootstrap_acc(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.015, alpha: float = 0.01, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedBAcc(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedBAcc(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci/2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "\n",
    "def bootstrap_f1(preds, targs, seed: int = 2021, n_bootstraps: int = 1000, ci: float = 0.015, alpha: float = 0.01, beta=1.0, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i  = resample(ids, stratify=targs.numpy(), random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(metrics_parallel)(CorrectedF1(alpha = alpha, beta= beta, threshold = 0.5, average=\"micro\"), preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    metric = CorrectedF1(alpha = alpha, beta = beta, threshold = 0.5, average=\"micro\")\n",
    "    \n",
    "    return {\"mean\": metric(preds, targs).numpy().item(), \"lower\": np.quantile(scores, ci/2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "def bootstrap_aul(preds, targs, seed: int = 2021, ci: float = 0.015, n_bootstraps: int = 1000, only_scores = False):\n",
    "    ids = np.arange(0, targs.shape[0], 1)\n",
    "    \n",
    "    idx = list()\n",
    "    for n in range(n_bootstraps):\n",
    "        i = resample(ids, stratify=targs, random_state=n)\n",
    "        if len(np.unique(targs[i])) < 2:\n",
    "                continue\n",
    "        idx.append(i)\n",
    "\n",
    "    executor = Parallel(n_jobs=7)\n",
    "    tasks = (delayed(return_aul)( preds[i], targs[i]) for i in idx)\n",
    "    scores = np.array(executor(tasks))\n",
    "    #### on full dataset\n",
    "    if only_scores:\n",
    "        return scores\n",
    "    \n",
    "    return {\"mean\": return_aul(preds, targs), \"lower\": np.quantile(scores, ci /2), \"upper\": np.quantile(scores, 1-ci/2)}\n",
    "\n",
    "\n",
    "def return_stats(path: str):\n",
    "    x  = load_stats(path)\n",
    "    start = time.time()\n",
    "    x[\"aul\"] = return_aul(preds = x[\"prb\"],  \n",
    "              targs = x[\"trg\"]) \n",
    "             # n_bootstraps=5000)\n",
    "    print(\"AUL is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"aul\"])\n",
    "    start = time.time()\n",
    "    x[\"mcc\"] = bootstrap_mcc(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n",
    "    print(\"MCC is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"mcc\"])\n",
    "\n",
    "    start = time.time()\n",
    "    x[\"acc\"] = bootstrap_acc(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n",
    "    print(\"ACC is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"acc\"])\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    x[\"f1\"] = bootstrap_f1(preds = torch.from_numpy(x[\"prb\"]),  \n",
    "              targs = torch.from_numpy(x[\"trg\"]).long(), \n",
    "              n_bootstraps=5000,\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n",
    "    print(\"F1 is done: %.2f s\" %(time.time()-start))\n",
    "    print(x[\"f1\"])\n",
    "    return x\n",
    "\n",
    "def contains_in_sequence(sample, min_, max_):\n",
    "    \"\"\"Checks if sequence contains tokens in range [min_, max_]\"\"\"\n",
    "    return np.where((sample >= min_) & (sample <=max_))[0].shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_stats(r\"O:\\\\projekter\\\\PY000017_D\\\\predictions\\\\v15\\\\emm\\\\emm_l2v\\\\%s\\\\\"%v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data[\"l2v\"] = return_stats(r\"O:\\\\projekter\\\\PY000017_D\\\\predictions\\\\v15\\\\emm\\\\emm_l2v\\\\%s\\\\\"%v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUL is done: 0.18 s\n",
      "0.7855556945228684\n",
      "MCC is done: 290.79 s\n",
      "{'mean': 0.14360277354717255, 'lower': 0.13583215933293105, 'upper': 0.15133474387228493}\n",
      "ACC is done: 287.64 s\n",
      "{'mean': 0.7135048508644104, 'lower': 0.7019722487032414, 'upper': 0.7250932790338993}\n",
      "F1 is done: 277.01 s\n",
      "{'mean': 0.10683707892894745, 'lower': 0.1037857998907566, 'upper': 0.10985342999920251}\n"
     ]
    }
   ],
   "source": [
    "data[\"rnn\"] = return_stats(r\"O:\\\\projekter\\\\PY000017_D\\\\predictions\\\\v15\\\\emm\\\\emm_rnn\\\\0.4\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_baselines = True\n",
    "if simple_baselines:\n",
    "    np.random.seed(0)\n",
    "    data[\"rnd\"] = {\"prb\": np.random.uniform(size=data[\"rnn\"][\"trg\"].shape[0]),\n",
    "               \"trg\": data[\"rnn\"][\"trg\"]}\n",
    "    data[\"rnd\"][\"aul\"] = return_aul(preds = data[\"rnd\"][\"prb\"],  \n",
    "                               targs = data[\"rnd\"][\"trg\"])\n",
    "    data[\"rnd\"][\"mcc\"] = bootstrap_mcc(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,1\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n",
    "    data[\"rnd\"][\"acc\"] = bootstrap_acc(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n",
    "    data[\"rnd\"][\"f1\"] = bootstrap_f1(preds = torch.from_numpy(data[\"rnd\"][\"prb\"]),  \n",
    "              targs = torch.from_numpy(data[\"rnd\"][\"trg\"]).long(), \n",
    "              n_bootstraps=1000,\n",
    "              alpha = 0.01,\n",
    "              beta=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data[\"mjr\"] = {\"prb\": np.random.uniform(high=0.5, size=data[\"rnn\"][\"trg\"].shape[0]),\n",
    "               \"trg\": data[\"rnn\"][\"trg\"]}\n",
    "data[\"mjr\"][\"aul\"] = return_aul(preds = data[\"mjr\"][\"prb\"],  \n",
    "                               targs = data[\"mjr\"][\"trg\"])\n",
    "data[\"mjr\"][\"mcc\"] = {\"mean\": return_mcc(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}\n",
    "data[\"mjr\"][\"acc\"] = {\"mean\": return_acc(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}\n",
    "data[\"mjr\"][\"f1\"] = {\"mean\": return_f1(preds = torch.from_numpy(data[\"mjr\"][\"prb\"]),  \n",
    "                               targs = torch.from_numpy(data[\"mjr\"][\"trg\"]).long()), \"lower\": np.nan, \"upper\": np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Error() \n",
    "    with open(save_path + \"metric.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data,f)\n",
    "except:\n",
    "    with open(save_path + \"metric.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUL\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"aul\"][\"mean\"], \n",
    "                                           data[key][\"aul\"][\"lower\"], \n",
    "                                           data[key][\"aul\"][\"upper\"]))\n",
    "print(\"MCC\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"mcc\"][\"mean\"], \n",
    "                                           data[key][\"mcc\"][\"lower\"], \n",
    "                                           data[key][\"mcc\"][\"upper\"]))\n",
    "print(\"ACC\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"acc\"][\"mean\"], \n",
    "                                           data[key][\"acc\"][\"lower\"], \n",
    "                                           data[key][\"acc\"][\"upper\"]))\n",
    "print(\"F1\")\n",
    "for key in data.keys():\n",
    "    print(\"\\t%s: %.3f [%.3f, %.3f]\" %(key, data[key][\"f1\"][\"mean\"], \n",
    "                                           data[key][\"f1\"][\"lower\"], \n",
    "                                           data[key][\"f1\"][\"upper\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
